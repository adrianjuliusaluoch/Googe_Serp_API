{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Data Collection Using Application Programming Interface (APIs)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Session 1 : Import Necessary Dependecies</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Session 2 : DataBase Test Code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transaction to DataBase[MySQL].\n",
      "Rows : 652\n",
      "Columns : 8\n",
      "Status ========> Complete.\n",
      "\n",
      "Open DataBase Connection Successfully Closed\n",
      "Status ========> Complete.\n",
      "All Done.\n"
     ]
    }
   ],
   "source": [
    "# db=mysql.connector.connect(user='data_miner',database='data_miner',password='data_mining')\n",
    "# cursor=db.cursor()\n",
    "# file=pd.read_csv('data_analyst_africa2.csv')\n",
    "# file['date_time']=datetime.datetime.now()\n",
    "# file=file[['title','company_name','via','location','description','extensions','detected_extensions','date_time']]\n",
    "# for number in file.iterrows():\n",
    "#     input=(\n",
    "#         'insert into data_science_jobs_in_africa'\n",
    "#         '(title,company_name,via,location,description,extensions,detected_extensions,date_time)'\n",
    "#         'values(%s,%s,%s,%s,%s,%s,%s,%s)')\n",
    "#     values=tuple(number[1])\n",
    "#     cursor.execute(input,values)\n",
    "#     db.commit()\n",
    "\n",
    "# cursor.close()\n",
    "# db.close()\n",
    "# print(f'Data Transaction to DataBase[MySQL].\\nRows : {file.shape[0]}\\nColumns : {file.shape[1]}\\nStatus ========> Complete.\\n'\n",
    "#     f'\\nOpen DataBase Connection Successfully Closed\\nStatus ========> Complete.\\nAll Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Session 3 : Configure API, Retrieve and Load Data to Local DataBase.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Page, ====> South Africa\n",
      "End of Page, ====> Egypt\n",
      "End of Page, ====> Uganda\n",
      "End of Page, ====> Nigeria\n",
      "End of Page, ====> Kenya\n",
      "\n",
      "Data Transaction to DataBase[MySQL]\n",
      "Shape of Collected Dataset\n",
      "Rows : 486\n",
      "Columns : 8\n",
      "\n",
      "Check & Remove Duplicate Records in the Data\n",
      "\n",
      "Statistics on Stored Data\n",
      "Shape of Dataset\n",
      "Rows : 1169\n",
      "Columns : 8\n"
     ]
    }
   ],
   "source": [
    "### Create an Open MySQL DataBase Connection\n",
    "db=mysql.connector.connect(user='data_miner',database='data_miner',password='data_mining')\n",
    "cursor=db.cursor()\n",
    "\n",
    "### Specify the Locations and Loop Variables\n",
    "countries=['South Africa','Egypt','Uganda','Nigeria','Kenya']\n",
    "jobs=[]\n",
    "start=0\n",
    "end=200\n",
    "page_size=10\n",
    "total_size=[]\n",
    "\n",
    "### Configure API, Retrieve and Load Data into you Local Machine's DataBase[MySQL]\n",
    "for country in countries:\n",
    "    try:\n",
    "        for index in range(start,end,page_size):\n",
    "            params = {\n",
    "            \"engine\": \"google_jobs\",\n",
    "            \"q\": \"Data Analyst\",\n",
    "            \"start\": index,\n",
    "            \"location\": country,\n",
    "            \"hl\": \"en\",\n",
    "            \"api_key\": \"5f2144edaebf008ed7b63d54e67b643fb234db105f28fd0409a29d67d0ce61aa\"\n",
    "            }\n",
    "            \n",
    "            search = GoogleSearch(params)\n",
    "            results = search.get_dict()\n",
    "            jobs_results = results[\"jobs_results\"]\n",
    "            jobs.append(jobs_results)\n",
    "            \n",
    "    except KeyError:\n",
    "        print(f'End of Page, ====> {country}')\n",
    "        \n",
    "### Loading Results to Local DataBase[MySQL]\n",
    "for index,content in enumerate(jobs):\n",
    "    jobs[index]=pd.DataFrame(content)\n",
    "    jobs[index].to_csv('data.csv',index=False)\n",
    "    data=pd.read_csv('data.csv')\n",
    "    data['date_time']=datetime.datetime.now()\n",
    "    data=data[['title','company_name','via','location','description','extensions','detected_extensions','date_time']]\n",
    "    total_size.append(data.shape[0])\n",
    "    for number in data.iterrows():\n",
    "        input=(\n",
    "                'insert into data_science_jobs_in_africa'\n",
    "                '(title,company_name,via,location,description,extensions,detected_extensions,date_time)'\n",
    "                'values(%s,%s,%s,%s,%s,%s,%s,%s)')\n",
    "        values=tuple(number[1])\n",
    "        cursor.execute(input,values)\n",
    "        db.commit()\n",
    "    os.remove('data.csv')\n",
    "\n",
    "### Close MySQL Open DataBase Connection\n",
    "cursor.close()\n",
    "db.close()\n",
    "print(f'\\nData Transaction to DataBase[MySQL]\\nShape of Collected Dataset\\nRows : {sum(total_size)}\\nColumns : {data.shape[1]}\\n')\n",
    "\n",
    "### Create MySQL Engine using SQLAlchemy\n",
    "mysql_engine=create_engine('mysql://data_miner:data_mining@localhost:3306/data_miner')\n",
    "results=pd.read_sql('data_science_jobs_in_africa',mysql_engine)\n",
    "print(f'Original Shape of Dataset in the MySQL DataBase\\nRows : {results.shape[0]}\\nColumns : {results.shape[1]}')\n",
    "\n",
    "### Check and Remove Duplicate Records\n",
    "dups=results.duplicated(subset=['title','company_name','via','location','description','extensions','detected_extensions']).sum()\n",
    "results.drop_duplicates(subset=['title','company_name','via','location','description','extensions','detected_extensions'],inplace=True)\n",
    "\n",
    "### Save Results to MySQL DataBase\n",
    "results.reset_index(drop=True,inplace=True)\n",
    "results.to_sql('data_science_jobs_in_africa',mysql_engine,if_exists='replace',index=False)\n",
    "print(f'Final Shape of Dataset in the MySQL DataBase after Dropping Duplicates\\nRows : {results.shape[0]}\\nColumns : {results.shape[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
